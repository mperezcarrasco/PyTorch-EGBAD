{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from train import TrainerEGBAD\n",
    "from preprocess import get_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    num_epochs=100\n",
    "    lr=0.00001\n",
    "    latent_dim=200\n",
    "    anormal_class=0\n",
    "    batch_size=100\n",
    "    \n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = get_mnist(args)\n",
    "\n",
    "egbad = TrainerEGBAD(args, data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43261/43261: [===============================>] - ETA 0.4sss\n",
      "Training... Epoch: 0, Discrimiantor Loss: 1.367, Generator Loss: 1.483\n",
      "43261/43261: [===============================>] - ETA 0.1ss\n",
      "Training... Epoch: 1, Discrimiantor Loss: 1.050, Generator Loss: 1.929\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 2, Discrimiantor Loss: 1.013, Generator Loss: 1.994\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 3, Discrimiantor Loss: 1.009, Generator Loss: 2.002\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 4, Discrimiantor Loss: 1.008, Generator Loss: 2.004\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 5, Discrimiantor Loss: 1.007, Generator Loss: 2.005\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 6, Discrimiantor Loss: 1.007, Generator Loss: 2.005\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 7, Discrimiantor Loss: 1.007, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 8, Discrimiantor Loss: 1.007, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 9, Discrimiantor Loss: 1.007, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 10, Discrimiantor Loss: 1.007, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.1ss\n",
      "Training... Epoch: 11, Discrimiantor Loss: 1.007, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 12, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 13, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 14, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 15, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 16, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 17, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 18, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 19, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 20, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 21, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 22, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 23, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 24, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 25, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 26, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 27, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 28, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 29, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 30, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.1ss\n",
      "Training... Epoch: 31, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 32, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 33, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 34, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 35, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 36, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 37, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 38, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 39, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 40, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.1ss\n",
      "Training... Epoch: 41, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 42, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 43, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 44, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 45, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 46, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 47, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 48, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 49, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 50, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 51, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 52, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 53, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 54, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 55, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 56, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 57, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 58, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 59, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 60, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 61, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 62, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 63, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 64, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 65, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 66, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 67, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 68, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 69, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 70, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.1ss\n",
      "Training... Epoch: 71, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 72, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 73, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 74, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 75, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 76, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "43261/43261: [===============================>] - ETA 0.0ss\n",
      "Training... Epoch: 77, Discrimiantor Loss: 1.006, Generator Loss: 2.006\n",
      "27700/43261: [====================>...........] - ETA 6.3ss"
     ]
    }
   ],
   "source": [
    "egbad.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "egbad.G.eval()\n",
    "egbad.D.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, label in data[1]:\n",
    "        img = img.float().to(device)\n",
    "        img_hat = egbad.G(egbad.E(img))\n",
    "        score_g = torch.sum(torch.abs(img - img_hat), dim=(1,2,3))\n",
    "        \n",
    "        y_true = Variable(torch.ones((img.size(0), 1)).to(self.device))\n",
    "        y_pred = egbad.D(img, egbad.E(img)).view(-1)\n",
    "        score_d = F.binary_cross_entropy(y_pred, y_true)\n",
    "        \n",
    "        score = alpha * score_g + (1-alpha)* score_d\n",
    "        scores.append(score.cpu())\n",
    "        labels.append(label.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.cat(scores, dim=0)\n",
    "labels = torch.cat(labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, auc\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels, scores)\n",
    "\n",
    "print('ROC AUC score: {:.2f}'.format(roc_auc_score(labels, scores)*100))\n",
    "print('PR AUC score: {:.2f}'.format(auc(recall, precision)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
